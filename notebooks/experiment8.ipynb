{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from egg import core\n",
    "from egg.zoo.simple_autoenc.features import OneHotLoader\n",
    "from egg.zoo.simple_autoenc.archs import Sender\n",
    "from egg.zoo.simple_autoenc.train import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = core.init(params=['--random_seed=13', \n",
    "                         '--n_epochs=50',\n",
    "                         '--batch_size=1'])\n",
    "opts.n_features = 10\n",
    "opts.batches_per_epoch = 1000\n",
    "opts.sender_entropy_coeff = 0.01\n",
    "opts.receiver_entropy_coeff = 0.01\n",
    "opts.executive_sender_entropy_coeff = 0.01\n",
    "opts.alphabet_size = 8\n",
    "opts.sender_population_size = 3\n",
    "opts.receiver_population_size = 3\n",
    "opts.lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output == sender_input.argmax(dim=1)).detach().float().mean(dim=0)\n",
    "    return -acc, {'acc': acc.item()}\n",
    "\n",
    "train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                            batches_per_epoch=opts.batches_per_epoch)\n",
    "test_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                            batches_per_epoch=opts.batches_per_epoch, seed=7)\n",
    "\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, n_hidden, n_features):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.output = core.RelaxedEmbedding(n_hidden, n_features)\n",
    "\n",
    "    def forward(self, x, _input):\n",
    "        return self.output(x)\n",
    "\n",
    "senders = [core.ReinforceWrapper(Sender(opts.alphabet_size, opts.n_features)) \n",
    "           for _ in range(opts.sender_population_size)]\n",
    "executive_senders = [core.ReinforceWrapper(Sender(opts.receiver_population_size, 1)) \n",
    "                     for _ in range(opts.sender_population_size)]\n",
    "receivers = [core.ReinforceWrapper(Receiver(opts.n_features, opts.alphabet_size)) \n",
    "             for _ in range(opts.receiver_population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentGame(nn.Module):\n",
    "\n",
    "    def __init__(self, senders, receivers, executive_senders, loss, \n",
    "                 sender_entropy_coeff=opts.sender_entropy_coeff, \n",
    "                 receiver_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                 executive_sender_entropy_coeff=opts.executive_sender_entropy_coeff):\n",
    "        super(MultiAgentGame, self).__init__()\n",
    "        self.senders = senders\n",
    "        self.receivers = receivers\n",
    "        self.executive_senders = executive_senders\n",
    "        self.loss = loss\n",
    "\n",
    "        self.receiver_entropy_coeff = receiver_entropy_coeff\n",
    "        self.sender_entropy_coeff = sender_entropy_coeff\n",
    "        self.executive_sender_entropy_coeff = executive_sender_entropy_coeff\n",
    "\n",
    "        self.mean_baseline = 0.0\n",
    "        self.n_points = 0.0\n",
    "\n",
    "    def forward(self, sender_input, labels, receiver_input=None):\n",
    "        idx = np.random.choice(len(self.senders))       \n",
    "        executive_sender = self.executive_senders[idx]\n",
    "        sender = self.senders[idx]\n",
    "        receiver_id, executive_sender_log_prob, executive_sender_entropy = executive_sender(torch.ones(1, 1))\n",
    "        receiver = self.receivers[receiver_id.item()]\n",
    "        message, sender_log_prob, sender_entropy = sender(sender_input)\n",
    "        receiver_output, receiver_log_prob, receiver_entropy = receiver(message, receiver_input)\n",
    "\n",
    "        loss, rest_info = self.loss(sender_input, message, receiver_input, receiver_output, labels)\n",
    "        advantage = (loss.detach() - self.mean_baseline) \n",
    "        sender_loss = advantage * (sender_log_prob + receiver_log_prob)\n",
    "        exec_sender_loss = advantage * (executive_sender_log_prob + receiver_log_prob)\n",
    "        receiver_loss = advantage * receiver_log_prob\n",
    "        policy_loss = (sender_loss + receiver_loss + exec_sender_loss).mean()\n",
    "        \n",
    "        entropy_loss = -(sender_entropy.mean() * self.sender_entropy_coeff + \n",
    "                         receiver_entropy.mean() * self.receiver_entropy_coeff +\n",
    "                         executive_sender_entropy.mean() * self.executive_sender_entropy_coeff)\n",
    "\n",
    "        if self.training:\n",
    "            self.n_points += 1.0\n",
    "            self.mean_baseline += (loss.detach().mean().item() -\n",
    "                                   self.mean_baseline) / self.n_points\n",
    "\n",
    "        full_loss = policy_loss + entropy_loss\n",
    "\n",
    "        rest_info['baseline'] = self.mean_baseline\n",
    "        rest_info['loss'] = loss.mean().item()\n",
    "        rest_info['sender_entropy'] = sender_entropy.mean()\n",
    "        rest_info['receiver_entropy'] = receiver_entropy.mean()\n",
    "        rest_info['executive_sender_entropy'] = executive_sender_entropy.mean()\n",
    "        return full_loss, rest_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "from neptune.experiments import Experiment\n",
    "\n",
    "\n",
    "class NeptuneMonitor:\n",
    "        \n",
    "    def __init__(self, experiment: Experiment = None):\n",
    "        self.experiment = experiment if experiment else neptune\n",
    "    \n",
    "    def log(self, mode, epoch, loss, rest):\n",
    "        self.experiment.send_metric(f'{mode}_loss', loss)\n",
    "        for metric, value in rest.items():\n",
    "            self.experiment.send_metric(f'{mode}_{metric}', value)\n",
    "\n",
    "            \n",
    "def save_sender_codebook(experiment, senders, epoch, label):\n",
    "    figure, axes = plt.subplots(1, len(receivers),sharey=True, figsize=(20,5))\n",
    "    figure.suptitle(f'Epoch {epoch}')\n",
    "    for i, (sender, ax) in enumerate(zip(senders, axes)):\n",
    "        g = sns.heatmap(F.softmax(sender.agent.fc1.weight.detach(), dim=1).numpy(), annot=True, fmt='.2f', ax=ax)\n",
    "        g.set_title(f'{label} {i}')\n",
    "    figure.savefig('fig.jpg')\n",
    "    experiment.log_image(f'{label}s', 'fig.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(core.Trainer):\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        while self.epoch < n_epochs:\n",
    "            train_loss, train_rest = self.train_epoch()\n",
    "            for i, ex_s in enumerate(self.game.executive_senders):\n",
    "                self.monitor.experiment.send_metric(f'ex sender {i} grad', ex_s.agent.fc1.weight.grad.sum())\n",
    "            for i, s in enumerate(self.game.senders):\n",
    "                self.monitor.experiment.send_metric(f'sender {i} grad', s.agent.fc1.weight.grad.sum())\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "            self.monitor.log('train', self.epoch, train_loss, train_rest)\n",
    "            \n",
    "\n",
    "            if self.validation_data is not None and self.validation_freq > 0 and self.epoch % self.validation_freq == 0:\n",
    "                validation_loss, rest = self.eval()\n",
    "                self.monitor.log('validation', self.epoch, validation_loss, rest)\n",
    "                print(f'validation: epoch {self.epoch}, loss {validation_loss},  {rest}', flush=True)\n",
    "                save_sender_codebook(self.monitor.experiment, self.game.senders, self.epoch, 'Sender')\n",
    "                save_sender_codebook(self.monitor.experiment, self.game.executive_senders, self.epoch, 'Executive sender')\n",
    "\n",
    "\n",
    "                if self.early_stopping:\n",
    "                    self.early_stopping.update_values(validation_loss, rest, train_loss, rest, self.epoch)\n",
    "                    if self.early_stopping.should_stop(): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGG-64\n",
      "https://ui.neptune.ml/tomekkorbak/egg/e/EGG-64\n",
      "validation: epoch 1, loss -0.006105861626565456,  {'acc': 0.115, 'baseline': -0.1009999999999993, 'loss': -0.115, 'sender_entropy': tensor(1.9241), 'receiver_entropy': tensor(1.7247), 'executive_sender_entropy': tensor(1.0272)}\n",
      "validation: epoch 2, loss -0.06182699277997017,  {'acc': 0.148, 'baseline': -0.11899999999999979, 'loss': -0.148, 'sender_entropy': tensor(1.7910), 'receiver_entropy': tensor(1.5497), 'executive_sender_entropy': tensor(1.0266)}\n",
      "validation: epoch 3, loss -0.04432927817106247,  {'acc': 0.186, 'baseline': -0.13766666666666397, 'loss': -0.186, 'sender_entropy': tensor(1.5320), 'receiver_entropy': tensor(1.3243), 'executive_sender_entropy': tensor(1.0242)}\n",
      "validation: epoch 4, loss -0.19516055285930634,  {'acc': 0.244, 'baseline': -0.1542499999999999, 'loss': -0.244, 'sender_entropy': tensor(1.3201), 'receiver_entropy': tensor(1.0149), 'executive_sender_entropy': tensor(1.0231)}\n",
      "validation: epoch 5, loss -0.15009166300296783,  {'acc': 0.327, 'baseline': -0.18459999999999827, 'loss': -0.327, 'sender_entropy': tensor(1.1038), 'receiver_entropy': tensor(0.7320), 'executive_sender_entropy': tensor(1.0195)}\n",
      "validation: epoch 6, loss -0.10454422980546951,  {'acc': 0.442, 'baseline': -0.2181666666666632, 'loss': -0.442, 'sender_entropy': tensor(0.8408), 'receiver_entropy': tensor(0.5932), 'executive_sender_entropy': tensor(1.0175)}\n",
      "validation: epoch 7, loss -0.0827518180012703,  {'acc': 0.487, 'baseline': -0.2562857142857182, 'loss': -0.487, 'sender_entropy': tensor(0.7738), 'receiver_entropy': tensor(0.4458), 'executive_sender_entropy': tensor(1.0139)}\n",
      "validation: epoch 8, loss -0.11425116658210754,  {'acc': 0.506, 'baseline': -0.28350000000000236, 'loss': -0.506, 'sender_entropy': tensor(0.6475), 'receiver_entropy': tensor(0.3741), 'executive_sender_entropy': tensor(1.0127)}\n",
      "validation: epoch 9, loss -0.05911540240049362,  {'acc': 0.561, 'baseline': -0.3125555555555523, 'loss': -0.561, 'sender_entropy': tensor(0.5686), 'receiver_entropy': tensor(0.3199), 'executive_sender_entropy': tensor(1.0079)}\n",
      "validation: epoch 10, loss 0.020531946793198586,  {'acc': 0.598, 'baseline': -0.33870000000000067, 'loss': -0.598, 'sender_entropy': tensor(0.5055), 'receiver_entropy': tensor(0.2469), 'executive_sender_entropy': tensor(1.0014)}\n",
      "validation: epoch 11, loss -0.09041222184896469,  {'acc': 0.596, 'baseline': -0.36236363636362984, 'loss': -0.596, 'sender_entropy': tensor(0.4720), 'receiver_entropy': tensor(0.1878), 'executive_sender_entropy': tensor(0.9980)}\n",
      "validation: epoch 12, loss -0.021082136780023575,  {'acc': 0.609, 'baseline': -0.3819166666666592, 'loss': -0.609, 'sender_entropy': tensor(0.4528), 'receiver_entropy': tensor(0.1531), 'executive_sender_entropy': tensor(0.9951)}\n",
      "validation: epoch 13, loss 0.013018056750297546,  {'acc': 0.64, 'baseline': -0.4001538461538425, 'loss': -0.64, 'sender_entropy': tensor(0.4491), 'receiver_entropy': tensor(0.1207), 'executive_sender_entropy': tensor(0.9920)}\n",
      "validation: epoch 14, loss -0.11510064452886581,  {'acc': 0.642, 'baseline': -0.41678571428570965, 'loss': -0.642, 'sender_entropy': tensor(0.4260), 'receiver_entropy': tensor(0.1326), 'executive_sender_entropy': tensor(0.9909)}\n",
      "validation: epoch 15, loss -0.11636817455291748,  {'acc': 0.649, 'baseline': -0.4313999999999973, 'loss': -0.649, 'sender_entropy': tensor(0.3981), 'receiver_entropy': tensor(0.1336), 'executive_sender_entropy': tensor(0.9900)}\n",
      "validation: epoch 16, loss -0.12339794635772705,  {'acc': 0.647, 'baseline': -0.4453750000000088, 'loss': -0.647, 'sender_entropy': tensor(0.3782), 'receiver_entropy': tensor(0.1322), 'executive_sender_entropy': tensor(0.9884)}\n",
      "validation: epoch 17, loss -0.1639411449432373,  {'acc': 0.659, 'baseline': -0.4567058823529361, 'loss': -0.659, 'sender_entropy': tensor(0.3721), 'receiver_entropy': tensor(0.1460), 'executive_sender_entropy': tensor(0.9907)}\n",
      "validation: epoch 18, loss -0.19089928269386292,  {'acc': 0.649, 'baseline': -0.4703888888888782, 'loss': -0.649, 'sender_entropy': tensor(0.3869), 'receiver_entropy': tensor(0.1449), 'executive_sender_entropy': tensor(0.9886)}\n",
      "validation: epoch 19, loss -0.14516833424568176,  {'acc': 0.677, 'baseline': -0.48005263157894057, 'loss': -0.677, 'sender_entropy': tensor(0.3638), 'receiver_entropy': tensor(0.1385), 'executive_sender_entropy': tensor(0.9887)}\n",
      "validation: epoch 20, loss -0.14169122278690338,  {'acc': 0.689, 'baseline': -0.48980000000000223, 'loss': -0.689, 'sender_entropy': tensor(0.3774), 'receiver_entropy': tensor(0.1345), 'executive_sender_entropy': tensor(0.9899)}\n",
      "validation: epoch 21, loss -0.16049906611442566,  {'acc': 0.686, 'baseline': -0.49900000000000977, 'loss': -0.686, 'sender_entropy': tensor(0.3264), 'receiver_entropy': tensor(0.1194), 'executive_sender_entropy': tensor(0.9887)}\n",
      "validation: epoch 22, loss -0.1334141045808792,  {'acc': 0.691, 'baseline': -0.5095454545454486, 'loss': -0.691, 'sender_entropy': tensor(0.3638), 'receiver_entropy': tensor(0.1240), 'executive_sender_entropy': tensor(0.9895)}\n",
      "validation: epoch 23, loss -0.2431095391511917,  {'acc': 0.693, 'baseline': -0.5174347826086896, 'loss': -0.693, 'sender_entropy': tensor(0.3244), 'receiver_entropy': tensor(0.1401), 'executive_sender_entropy': tensor(0.9893)}\n",
      "validation: epoch 24, loss -0.2268267720937729,  {'acc': 0.695, 'baseline': -0.5236666666666586, 'loss': -0.695, 'sender_entropy': tensor(0.3599), 'receiver_entropy': tensor(0.1444), 'executive_sender_entropy': tensor(0.9883)}\n",
      "validation: epoch 25, loss -0.1960216909646988,  {'acc': 0.709, 'baseline': -0.5302399999999949, 'loss': -0.709, 'sender_entropy': tensor(0.3423), 'receiver_entropy': tensor(0.1324), 'executive_sender_entropy': tensor(0.9891)}\n",
      "validation: epoch 26, loss -0.1305268108844757,  {'acc': 0.732, 'baseline': -0.5373461538461548, 'loss': -0.732, 'sender_entropy': tensor(0.2850), 'receiver_entropy': tensor(0.1023), 'executive_sender_entropy': tensor(0.9875)}\n",
      "validation: epoch 27, loss -0.07343220710754395,  {'acc': 0.744, 'baseline': -0.544555555555563, 'loss': -0.744, 'sender_entropy': tensor(0.3040), 'receiver_entropy': tensor(0.0772), 'executive_sender_entropy': tensor(0.9851)}\n",
      "validation: epoch 28, loss -0.068605437874794,  {'acc': 0.743, 'baseline': -0.5519642857142847, 'loss': -0.743, 'sender_entropy': tensor(0.3142), 'receiver_entropy': tensor(0.0435), 'executive_sender_entropy': tensor(0.9820)}\n",
      "validation: epoch 29, loss -0.019414236769080162,  {'acc': 0.739, 'baseline': -0.5583103448275839, 'loss': -0.739, 'sender_entropy': tensor(0.2766), 'receiver_entropy': tensor(0.0299), 'executive_sender_entropy': tensor(0.9818)}\n",
      "validation: epoch 30, loss -0.08803890645503998,  {'acc': 0.748, 'baseline': -0.5644333333333381, 'loss': -0.748, 'sender_entropy': tensor(0.2883), 'receiver_entropy': tensor(0.0793), 'executive_sender_entropy': tensor(0.9816)}\n",
      "validation: epoch 31, loss -0.030624469742178917,  {'acc': 0.786, 'baseline': -0.5717419354838699, 'loss': -0.786, 'sender_entropy': tensor(0.2419), 'receiver_entropy': tensor(0.0368), 'executive_sender_entropy': tensor(0.9798)}\n",
      "validation: epoch 32, loss 0.013814183883368969,  {'acc': 0.792, 'baseline': -0.5788125000000139, 'loss': -0.792, 'sender_entropy': tensor(0.2098), 'receiver_entropy': tensor(0.0273), 'executive_sender_entropy': tensor(0.9777)}\n",
      "validation: epoch 33, loss 0.012058192864060402,  {'acc': 0.791, 'baseline': -0.5849393939394046, 'loss': -0.791, 'sender_entropy': tensor(0.2374), 'receiver_entropy': tensor(0.0226), 'executive_sender_entropy': tensor(0.9782)}\n",
      "validation: epoch 34, loss 0.05089205503463745,  {'acc': 0.797, 'baseline': -0.5919705882353034, 'loss': -0.797, 'sender_entropy': tensor(0.2080), 'receiver_entropy': tensor(0.0181), 'executive_sender_entropy': tensor(0.9802)}\n",
      "validation: epoch 35, loss 0.031689032912254333,  {'acc': 0.795, 'baseline': -0.5978571428571505, 'loss': -0.795, 'sender_entropy': tensor(0.2146), 'receiver_entropy': tensor(0.0155), 'executive_sender_entropy': tensor(0.9814)}\n",
      "validation: epoch 36, loss -0.0029191211797297,  {'acc': 0.796, 'baseline': -0.6035277777777895, 'loss': -0.796, 'sender_entropy': tensor(0.2580), 'receiver_entropy': tensor(0.0131), 'executive_sender_entropy': tensor(0.9820)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: epoch 37, loss 0.014040905050933361,  {'acc': 0.796, 'baseline': -0.6088378378378433, 'loss': -0.796, 'sender_entropy': tensor(0.2425), 'receiver_entropy': tensor(0.0102), 'executive_sender_entropy': tensor(0.9847)}\n",
      "validation: epoch 38, loss 0.03705231100320816,  {'acc': 0.797, 'baseline': -0.613500000000006, 'loss': -0.797, 'sender_entropy': tensor(0.2197), 'receiver_entropy': tensor(0.0079), 'executive_sender_entropy': tensor(0.9847)}\n",
      "validation: epoch 39, loss -0.001573710236698389,  {'acc': 0.797, 'baseline': -0.6178974358974395, 'loss': -0.797, 'sender_entropy': tensor(0.2603), 'receiver_entropy': tensor(0.0065), 'executive_sender_entropy': tensor(0.9836)}\n",
      "validation: epoch 40, loss 0.014994163066148758,  {'acc': 0.796, 'baseline': -0.6229250000000087, 'loss': -0.796, 'sender_entropy': tensor(0.2191), 'receiver_entropy': tensor(0.0052), 'executive_sender_entropy': tensor(0.9829)}\n",
      "validation: epoch 41, loss -0.0018142202170565724,  {'acc': 0.796, 'baseline': -0.6270731707317062, 'loss': -0.796, 'sender_entropy': tensor(0.2466), 'receiver_entropy': tensor(0.0050), 'executive_sender_entropy': tensor(0.9856)}\n",
      "validation: epoch 42, loss -0.053469620645046234,  {'acc': 0.794, 'baseline': -0.6309285714285822, 'loss': -0.794, 'sender_entropy': tensor(0.2470), 'receiver_entropy': tensor(0.0075), 'executive_sender_entropy': tensor(0.9836)}\n",
      "validation: epoch 43, loss -0.017861945554614067,  {'acc': 0.796, 'baseline': -0.6342325581395384, 'loss': -0.796, 'sender_entropy': tensor(0.2559), 'receiver_entropy': tensor(0.0055), 'executive_sender_entropy': tensor(0.9834)}\n",
      "validation: epoch 44, loss -0.023362325504422188,  {'acc': 0.797, 'baseline': -0.6375909090909225, 'loss': -0.797, 'sender_entropy': tensor(0.2562), 'receiver_entropy': tensor(0.0045), 'executive_sender_entropy': tensor(0.9833)}\n",
      "validation: epoch 45, loss -0.02684614807367325,  {'acc': 0.796, 'baseline': -0.6413555555555631, 'loss': -0.796, 'sender_entropy': tensor(0.2330), 'receiver_entropy': tensor(0.0049), 'executive_sender_entropy': tensor(0.9828)}\n",
      "validation: epoch 46, loss -0.05313319340348244,  {'acc': 0.796, 'baseline': -0.6446739130434825, 'loss': -0.796, 'sender_entropy': tensor(0.2479), 'receiver_entropy': tensor(0.0086), 'executive_sender_entropy': tensor(0.9836)}\n",
      "validation: epoch 47, loss -0.03774275630712509,  {'acc': 0.796, 'baseline': -0.647978723404252, 'loss': -0.796, 'sender_entropy': tensor(0.2407), 'receiver_entropy': tensor(0.0189), 'executive_sender_entropy': tensor(0.9816)}\n",
      "validation: epoch 48, loss -0.13168050348758698,  {'acc': 0.791, 'baseline': -0.651416666666671, 'loss': -0.791, 'sender_entropy': tensor(0.2928), 'receiver_entropy': tensor(0.0350), 'executive_sender_entropy': tensor(0.9842)}\n",
      "validation: epoch 49, loss -0.12824806571006775,  {'acc': 0.792, 'baseline': -0.6548979591836892, 'loss': -0.792, 'sender_entropy': tensor(0.2886), 'receiver_entropy': tensor(0.0249), 'executive_sender_entropy': tensor(0.9805)}\n",
      "validation: epoch 50, loss -0.057887181639671326,  {'acc': 0.795, 'baseline': -0.6577200000000051, 'loss': -0.795, 'sender_entropy': tensor(0.2326), 'receiver_entropy': tensor(0.0153), 'executive_sender_entropy': tensor(0.9818)}\n"
     ]
    }
   ],
   "source": [
    "game = MultiAgentGame(senders, receivers, executive_senders, loss)\n",
    "sender_params = [{'params': sender.parameters(), 'lr': opts.lr} for sender in senders]\n",
    "executive_senders_params = [{'params': ex_sender.parameters(), 'lr': opts.lr*0.01} for ex_sender in executive_senders]\n",
    "receiver_params = [{'params': receiver.parameters(), 'lr': opts.lr} for receiver in receivers]\n",
    "optimizer = torch.optim.Adam(sender_params+receiver_params+executive_senders_params)\n",
    "\n",
    "neptune.init('tomekkorbak/EGG')\n",
    "trainer = CustomTrainer(game=game, optimizer=optimizer, train_data=train_loader, validation_data=test_loader)\n",
    "experiment = neptune.create_experiment(name='first-egg-experiment', tags=['egg', 'executive-senders'], params=vars(opts))\n",
    "trainer.monitor = NeptuneMonitor(experiment=experiment)\n",
    "trainer.train(n_epochs=opts.n_epochs)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "neptune": {
   "notebookId": "b69eb419-3ef8-46f1-98ea-abeb77b5106e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
