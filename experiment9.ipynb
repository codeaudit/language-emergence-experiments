{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from egg import core\n",
    "from egg.zoo.simple_autoenc.features import OneHotLoader\n",
    "from egg.zoo.simple_autoenc.archs import Sender\n",
    "from egg.zoo.simple_autoenc.train import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = core.init(params=['--random_seed=13', \n",
    "                         '--n_epochs=50',\n",
    "                         '--batch_size=1'])\n",
    "opts.n_features = 10\n",
    "opts.batches_per_epoch = 1000\n",
    "opts.sender_entropy_coeff = 0.01\n",
    "opts.receiver_entropy_coeff = 0.01\n",
    "opts.executive_sender_entropy_coeff = 0.01\n",
    "opts.alphabet_size = 8\n",
    "opts.sender_population_size = 1\n",
    "opts.receiver_population_size = 3\n",
    "opts.lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output == sender_input.argmax(dim=1)).detach().float().mean(dim=0)\n",
    "    return -acc, {'acc': acc.item()}\n",
    "\n",
    "train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                            batches_per_epoch=opts.batches_per_epoch)\n",
    "test_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                            batches_per_epoch=opts.batches_per_epoch, seed=7)\n",
    "\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, n_hidden, n_features):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.output = core.RelaxedEmbedding(n_hidden, n_features)\n",
    "\n",
    "    def forward(self, x, _input):\n",
    "        return self.output(x)\n",
    "\n",
    "senders = [core.ReinforceWrapper(Sender(opts.alphabet_size, opts.n_features)) \n",
    "           for _ in range(opts.sender_population_size)]\n",
    "executive_senders = [core.ReinforceWrapper(Sender(opts.receiver_population_size, 1)) \n",
    "                     for _ in range(opts.sender_population_size)]\n",
    "receivers = [core.ReinforceWrapper(Receiver(opts.n_features, opts.alphabet_size)) \n",
    "             for _ in range(opts.receiver_population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentGame(nn.Module):\n",
    "\n",
    "    def __init__(self, senders, receivers, executive_senders, loss, \n",
    "                 sender_entropy_coeff=opts.sender_entropy_coeff, \n",
    "                 receiver_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                 executive_sender_entropy_coeff=opts.executive_sender_entropy_coeff):\n",
    "        super(MultiAgentGame, self).__init__()\n",
    "        self.senders = senders\n",
    "        self.receivers = receivers\n",
    "        self.executive_senders = executive_senders\n",
    "        self.loss = loss\n",
    "\n",
    "        self.receiver_entropy_coeff = receiver_entropy_coeff\n",
    "        self.sender_entropy_coeff = sender_entropy_coeff\n",
    "        self.executive_sender_entropy_coeff = executive_sender_entropy_coeff\n",
    "\n",
    "        self.mean_baseline = 0.0\n",
    "        self.n_points = 0.0\n",
    "\n",
    "    def forward(self, sender_input, labels, receiver_input=None):\n",
    "        idx = np.random.choice(len(self.senders))       \n",
    "        executive_sender = self.executive_senders[idx]\n",
    "        sender = self.senders[idx]\n",
    "        receiver_id, executive_sender_log_prob, executive_sender_entropy = executive_sender(torch.ones(1, 1))\n",
    "        receiver = self.receivers[receiver_id.item()]\n",
    "        message, sender_log_prob, sender_entropy = sender(sender_input)\n",
    "        receiver_output, receiver_log_prob, receiver_entropy = receiver(message, receiver_input)\n",
    "\n",
    "        loss, rest_info = self.loss(sender_input, message, receiver_input, receiver_output, labels)\n",
    "        advantage = (loss.detach() - self.mean_baseline) \n",
    "        sender_loss = advantage * (sender_log_prob + receiver_log_prob)\n",
    "        exec_sender_loss = advantage * (executive_sender_log_prob + receiver_log_prob)\n",
    "        receiver_loss = advantage * receiver_log_prob\n",
    "        policy_loss = (sender_loss + receiver_loss + exec_sender_loss).mean()\n",
    "        \n",
    "        entropy_loss = -(sender_entropy.mean() * self.sender_entropy_coeff + \n",
    "                         receiver_entropy.mean() * self.receiver_entropy_coeff +\n",
    "                         executive_sender_entropy.mean() * self.executive_sender_entropy_coeff)\n",
    "\n",
    "        if self.training:\n",
    "            self.n_points += 1.0\n",
    "            self.mean_baseline += (loss.detach().mean().item() -\n",
    "                                   self.mean_baseline) / self.n_points\n",
    "\n",
    "        full_loss = policy_loss + entropy_loss\n",
    "\n",
    "        rest_info['baseline'] = self.mean_baseline\n",
    "        rest_info['loss'] = loss.mean().item()\n",
    "        rest_info['sender_entropy'] = sender_entropy.mean()\n",
    "        rest_info['receiver_entropy'] = receiver_entropy.mean()\n",
    "        rest_info['executive_sender_entropy'] = executive_sender_entropy.mean()\n",
    "        return full_loss, rest_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "from neptune.experiments import Experiment\n",
    "\n",
    "\n",
    "class NeptuneMonitor:\n",
    "        \n",
    "    def __init__(self, experiment: Experiment = None):\n",
    "        self.experiment = experiment if experiment else neptune\n",
    "    \n",
    "    def log(self, mode, epoch, loss, rest):\n",
    "        self.experiment.send_metric(f'{mode}_loss', loss)\n",
    "        for metric, value in rest.items():\n",
    "            self.experiment.send_metric(f'{mode}_{metric}', value)\n",
    "\n",
    "            \n",
    "def save_sender_codebook(experiment, senders, epoch, label):\n",
    "    figure, axes = plt.subplots(1, len(receivers),sharey=True, figsize=(20,5))\n",
    "    figure.suptitle(f'Epoch {epoch}')\n",
    "    for i, (sender, ax) in enumerate(zip(senders, axes)):\n",
    "        g = sns.heatmap(F.softmax(sender.agent.fc1.weight.detach(), dim=1).numpy(), annot=True, fmt='.2f', ax=ax)\n",
    "        g.set_title(f'{label} {i}')\n",
    "    figure.savefig('fig.jpg')\n",
    "    experiment.log_image(f'{label}s', 'fig.jpg')\n",
    "    plt.close()\n",
    "    \n",
    "def save_exec_sender_codebook(experiment, senders, epoch, label):\n",
    "    figure, axes = plt.subplots(1, len(receivers),sharey=True, figsize=(20,5))\n",
    "    figure.suptitle(f'Epoch {epoch}')\n",
    "    for i, (sender, ax) in enumerate(zip(senders, axes)):\n",
    "        g = sns.heatmap(F.softmax(sender.agent.fc1.weight.detach(), dim=1).numpy(), annot=True, fmt='.2f', ax=ax)\n",
    "        g.set_title(f'{label} {i}')\n",
    "    figure.savefig('fig.jpg')\n",
    "    experiment.log_image(f'{label}s', 'fig.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def is_codebook_shared(senders):\n",
    "    from itertools import product\n",
    "    return all(shared_codebooks(sender1, sender2) \n",
    "               for sender1, sender2 in product(senders, senders))\n",
    "\n",
    "\n",
    "def shared_codebooks(sender1, sender2):\n",
    "    return bool(((sender1.agent.fc1.weight.detach()).argmax(dim=1) == \\\n",
    "               (sender2.agent.fc1.weight.detach()).argmax(dim=1)).all())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(core.Trainer):\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        while self.epoch < n_epochs:\n",
    "            train_loss, train_rest = self.train_epoch()\n",
    "            for i, ex_s in enumerate(self.game.executive_senders):\n",
    "                self.monitor.experiment.send_metric(f'ex sender {i} grad', ex_s.agent.fc1.weight.grad.sum())\n",
    "            for i, s in enumerate(self.game.senders):\n",
    "                self.monitor.experiment.send_metric(f'sender {i} grad', s.agent.fc1.weight.grad.sum())\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "            self.monitor.log('train', self.epoch, train_loss, train_rest)\n",
    "            self.monitor.experiment.send_metric('shared_codebook', is_codebook_shared(self.game.senders))\n",
    "\n",
    "\n",
    "            if self.validation_data is not None and self.validation_freq > 0 and self.epoch % self.validation_freq == 0:\n",
    "                validation_loss, rest = self.eval()\n",
    "                self.monitor.log('validation', self.epoch, validation_loss, rest)\n",
    "                print(f'validation: epoch {self.epoch}, loss {validation_loss},  {rest}', flush=True)\n",
    "                save_sender_codebook(self.monitor.experiment, self.game.senders, self.epoch, 'Sender')\n",
    "                save_exec_sender_codebook(self.monitor.experiment, self.game.executive_senders, self.epoch, 'Executive sender')\n",
    "\n",
    "\n",
    "                if self.early_stopping:\n",
    "                    self.early_stopping.update_values(validation_loss, rest, train_loss, rest, self.epoch)\n",
    "                    if self.early_stopping.should_stop(): break\n",
    "        \n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGG-84\n",
      "https://ui.neptune.ml/tomekkorbak/egg/e/EGG-84\n",
      "validation: epoch 1, loss -0.025697851553559303,  {'acc': 0.39, 'baseline': -0.33400000000000285, 'loss': -0.39, 'sender_entropy': tensor(0.0437), 'receiver_entropy': tensor(0.0453), 'executive_sender_entropy': tensor(0.0142)}\n",
      "validation: epoch 2, loss -0.03087226301431656,  {'acc': 0.496, 'baseline': -0.4180000000000053, 'loss': -0.496, 'sender_entropy': tensor(0.0500), 'receiver_entropy': tensor(0.0082), 'executive_sender_entropy': tensor(0.0012)}\n",
      "validation: epoch 3, loss -0.013852248899638653,  {'acc': 0.497, 'baseline': -0.43766666666665943, 'loss': -0.497, 'sender_entropy': tensor(0.0193), 'receiver_entropy': tensor(0.0082), 'executive_sender_entropy': tensor(0.0012)}\n",
      "validation: epoch 4, loss -0.014215932227671146,  {'acc': 0.497, 'baseline': -0.45125000000000365, 'loss': -0.497, 'sender_entropy': tensor(0.0275), 'receiver_entropy': tensor(0.0037), 'executive_sender_entropy': tensor(0.0014)}\n",
      "validation: epoch 5, loss -0.15761533379554749,  {'acc': 0.482, 'baseline': -0.454400000000006, 'loss': -0.482, 'sender_entropy': tensor(0.0093), 'receiver_entropy': tensor(0.1458), 'executive_sender_entropy': tensor(0.0023)}\n",
      "validation: epoch 6, loss -0.03139077126979828,  {'acc': 0.499, 'baseline': -0.4619999999999923, 'loss': -0.499, 'sender_entropy': tensor(0.0008), 'receiver_entropy': tensor(0.0081), 'executive_sender_entropy': tensor(0.0059)}\n",
      "validation: epoch 7, loss -0.0008744016522541642,  {'acc': 0.5, 'baseline': -0.461571428571419, 'loss': -0.5, 'sender_entropy': tensor(0.0038), 'receiver_entropy': tensor(0.0095), 'executive_sender_entropy': tensor(0.0020)}\n",
      "validation: epoch 8, loss -0.021792517974972725,  {'acc': 0.5, 'baseline': -0.46649999999999714, 'loss': -0.5, 'sender_entropy': tensor(0.0002), 'receiver_entropy': tensor(0.0068), 'executive_sender_entropy': tensor(3.0412e-06)}\n",
      "validation: epoch 9, loss -0.011207815259695053,  {'acc': 0.5, 'baseline': -0.4697777777777788, 'loss': -0.5, 'sender_entropy': tensor(0.0001), 'receiver_entropy': tensor(0.0027), 'executive_sender_entropy': tensor(3.0480e-06)}\n",
      "validation: epoch 10, loss -0.0014658416621387005,  {'acc': 0.5, 'baseline': -0.4726, 'loss': -0.5, 'sender_entropy': tensor(8.5037e-05), 'receiver_entropy': tensor(0.0110), 'executive_sender_entropy': tensor(3.0603e-06)}\n",
      "validation: epoch 11, loss -0.020210355520248413,  {'acc': 0.499, 'baseline': -0.47427272727271974, 'loss': -0.499, 'sender_entropy': tensor(7.3541e-05), 'receiver_entropy': tensor(0.0055), 'executive_sender_entropy': tensor(3.0831e-06)}\n",
      "validation: epoch 12, loss -0.00023299644817598164,  {'acc': 0.5, 'baseline': -0.47725000000001133, 'loss': -0.5, 'sender_entropy': tensor(8.1131e-05), 'receiver_entropy': tensor(0.0023), 'executive_sender_entropy': tensor(3.1159e-06)}\n",
      "validation: epoch 13, loss -0.00037659317604266107,  {'acc': 0.5, 'baseline': -0.4820769230769287, 'loss': -0.5, 'sender_entropy': tensor(0.0003), 'receiver_entropy': tensor(0.0033), 'executive_sender_entropy': tensor(3.1619e-06)}\n",
      "validation: epoch 14, loss -0.011820178478956223,  {'acc': 0.5, 'baseline': -0.48371428571429853, 'loss': -0.5, 'sender_entropy': tensor(1.7043e-05), 'receiver_entropy': tensor(0.0054), 'executive_sender_entropy': tensor(3.2676e-06)}\n",
      "validation: epoch 15, loss -0.00012947538925800472,  {'acc': 0.5, 'baseline': -0.48526666666667506, 'loss': -0.5, 'sender_entropy': tensor(1.0110e-05), 'receiver_entropy': tensor(0.0013), 'executive_sender_entropy': tensor(3.4546e-06)}\n",
      "validation: epoch 16, loss -0.00020900194067507982,  {'acc': 0.5, 'baseline': -0.4864375000000101, 'loss': -0.5, 'sender_entropy': tensor(7.9115e-06), 'receiver_entropy': tensor(0.0019), 'executive_sender_entropy': tensor(3.9237e-06)}\n",
      "validation: epoch 17, loss -9.530332135909703e-06,  {'acc': 0.5, 'baseline': -0.4869411764705802, 'loss': -0.5, 'sender_entropy': tensor(6.9343e-06), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(5.0558e-06)}\n",
      "validation: epoch 18, loss -8.775099558988586e-06,  {'acc': 0.5, 'baseline': -0.4892222222222244, 'loss': -0.5, 'sender_entropy': tensor(6.4132e-06), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(9.0854e-06)}\n",
      "validation: epoch 19, loss -8.784274541540071e-06,  {'acc': 0.5, 'baseline': -0.48968421052632016, 'loss': -0.5, 'sender_entropy': tensor(6.3187e-06), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(6.5606e-06)}\n",
      "validation: epoch 20, loss -3.831227877526544e-05,  {'acc': 0.5, 'baseline': -0.48930000000001056, 'loss': -0.5, 'sender_entropy': tensor(6.6699e-06), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(0.0032)}\n",
      "validation: epoch 21, loss -1.1687181540764868e-05,  {'acc': 0.5, 'baseline': -0.48928571428571105, 'loss': -0.5, 'sender_entropy': tensor(1.0274e-05), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(1.3681e-07)}\n",
      "validation: epoch 22, loss -1.55114885274088e-05,  {'acc': 0.5, 'baseline': -0.48990909090908064, 'loss': -0.5, 'sender_entropy': tensor(0.0002), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(1.3742e-07)}\n",
      "validation: epoch 23, loss -0.0002765287063084543,  {'acc': 0.5, 'baseline': -0.49152173913044767, 'loss': -0.5, 'sender_entropy': tensor(0.0002), 'receiver_entropy': tensor(0.0044), 'executive_sender_entropy': tensor(1.3830e-07)}\n",
      "validation: epoch 24, loss -0.009765778668224812,  {'acc': 0.486, 'baseline': -0.49304166666666993, 'loss': -0.486, 'sender_entropy': tensor(0.0002), 'receiver_entropy': tensor(0.0080), 'executive_sender_entropy': tensor(1.3981e-07)}\n",
      "validation: epoch 25, loss -9.784613212104887e-05,  {'acc': 0.487, 'baseline': -0.49344000000000904, 'loss': -0.487, 'sender_entropy': tensor(0.0008), 'receiver_entropy': tensor(0.0008), 'executive_sender_entropy': tensor(1.4279e-07)}\n",
      "validation: epoch 26, loss -8.04302326287143e-05,  {'acc': 0.487, 'baseline': -0.4941153846153839, 'loss': -0.487, 'sender_entropy': tensor(0.0002), 'receiver_entropy': tensor(0.0011), 'executive_sender_entropy': tensor(1.4779e-07)}\n",
      "validation: epoch 27, loss -0.032786231487989426,  {'acc': 0.486, 'baseline': -0.4940740740740808, 'loss': -0.486, 'sender_entropy': tensor(0.0290), 'receiver_entropy': tensor(0.0057), 'executive_sender_entropy': tensor(1.5806e-07)}\n",
      "validation: epoch 28, loss -1.2293556210352108e-05,  {'acc': 0.487, 'baseline': -0.49478571428572565, 'loss': -0.487, 'sender_entropy': tensor(0.0001), 'receiver_entropy': tensor(6.2213e-05), 'executive_sender_entropy': tensor(1.7588e-07)}\n",
      "validation: epoch 29, loss -3.506840585032478e-06,  {'acc': 0.487, 'baseline': -0.49431034482757963, 'loss': -0.487, 'sender_entropy': tensor(4.3428e-07), 'receiver_entropy': tensor(6.1139e-05), 'executive_sender_entropy': tensor(2.2689e-07)}\n",
      "validation: epoch 30, loss -4.96578059028252e-06,  {'acc': 0.487, 'baseline': -0.49380000000000773, 'loss': -0.487, 'sender_entropy': tensor(3.0038e-07), 'receiver_entropy': tensor(6.3194e-05), 'executive_sender_entropy': tensor(4.2501e-07)}\n",
      "validation: epoch 31, loss -5.185418103792472e-06,  {'acc': 0.487, 'baseline': -0.49480645161291603, 'loss': -0.487, 'sender_entropy': tensor(2.6584e-07), 'receiver_entropy': tensor(6.6506e-05), 'executive_sender_entropy': tensor(1.6890e-05)}\n",
      "validation: epoch 32, loss -6.797377409384353e-06,  {'acc': 0.487, 'baseline': -0.4951874999999896, 'loss': -0.487, 'sender_entropy': tensor(2.4753e-07), 'receiver_entropy': tensor(7.5978e-05), 'executive_sender_entropy': tensor(2.2481e-05)}\n",
      "validation: epoch 33, loss -8.423309736826923e-06,  {'acc': 0.487, 'baseline': -0.4954848484848529, 'loss': -0.487, 'sender_entropy': tensor(2.3707e-07), 'receiver_entropy': tensor(0.0001), 'executive_sender_entropy': tensor(4.1500e-05)}\n",
      "validation: epoch 34, loss -3.548684253473766e-05,  {'acc': 0.487, 'baseline': -0.4961176470588347, 'loss': -0.487, 'sender_entropy': tensor(2.3027e-07), 'receiver_entropy': tensor(0.0003), 'executive_sender_entropy': tensor(0.0004)}\n",
      "validation: epoch 35, loss -0.028437413275241852,  {'acc': 0.5, 'baseline': -0.4965428571428563, 'loss': -0.5, 'sender_entropy': tensor(2.2657e-07), 'receiver_entropy': tensor(0.0011), 'executive_sender_entropy': tensor(0.0001)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: epoch 36, loss -0.012845792807638645,  {'acc': 0.5, 'baseline': -0.49708333333332216, 'loss': -0.5, 'sender_entropy': tensor(2.2438e-07), 'receiver_entropy': tensor(0.0017), 'executive_sender_entropy': tensor(0.0001)}\n",
      "validation: epoch 37, loss -0.0412503182888031,  {'acc': 0.498, 'baseline': -0.4974594594594496, 'loss': -0.498, 'sender_entropy': tensor(2.2372e-07), 'receiver_entropy': tensor(0.0287), 'executive_sender_entropy': tensor(1.3268e-08)}\n",
      "validation: epoch 38, loss -0.015549964271485806,  {'acc': 0.5, 'baseline': -0.49697368421051674, 'loss': -0.5, 'sender_entropy': tensor(2.2535e-07), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3267e-08)}\n",
      "validation: epoch 39, loss -4.0327948227059096e-05,  {'acc': 0.5, 'baseline': -0.4960256410256504, 'loss': -0.5, 'sender_entropy': tensor(2.2938e-07), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3267e-08)}\n",
      "validation: epoch 40, loss -6.206531543284655e-05,  {'acc': 0.5, 'baseline': -0.495650000000009, 'loss': -0.5, 'sender_entropy': tensor(2.3658e-07), 'receiver_entropy': tensor(0.0007), 'executive_sender_entropy': tensor(1.3267e-08)}\n",
      "validation: epoch 41, loss -0.0005320853088051081,  {'acc': 0.5, 'baseline': -0.49604878048780005, 'loss': -0.5, 'sender_entropy': tensor(2.5171e-07), 'receiver_entropy': tensor(0.0044), 'executive_sender_entropy': tensor(1.3267e-08)}\n",
      "validation: epoch 42, loss -6.915105041116476e-05,  {'acc': 0.5, 'baseline': -0.49583333333333696, 'loss': -0.5, 'sender_entropy': tensor(2.8321e-07), 'receiver_entropy': tensor(0.0007), 'executive_sender_entropy': tensor(1.3267e-08)}\n",
      "validation: epoch 43, loss -0.00011820986401289701,  {'acc': 0.5, 'baseline': -0.49548837209301827, 'loss': -0.5, 'sender_entropy': tensor(3.8871e-07), 'receiver_entropy': tensor(0.0012), 'executive_sender_entropy': tensor(1.3268e-08)}\n",
      "validation: epoch 44, loss -3.67181419278495e-05,  {'acc': 0.5, 'baseline': -0.49579545454544444, 'loss': -0.5, 'sender_entropy': tensor(9.9877e-07), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3269e-08)}\n",
      "validation: epoch 45, loss -0.015309730544686317,  {'acc': 0.5, 'baseline': -0.49591111111112324, 'loss': -0.5, 'sender_entropy': tensor(0.0011), 'receiver_entropy': tensor(0.0003), 'executive_sender_entropy': tensor(1.3271e-08)}\n",
      "validation: epoch 46, loss -0.00016165495617315173,  {'acc': 0.498, 'baseline': -0.49586956521739034, 'loss': -0.498, 'sender_entropy': tensor(0.0018), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3275e-08)}\n",
      "validation: epoch 47, loss -0.006385426037013531,  {'acc': 0.498, 'baseline': -0.4961276595744724, 'loss': -0.498, 'sender_entropy': tensor(0.0250), 'receiver_entropy': tensor(0.0003), 'executive_sender_entropy': tensor(1.3281e-08)}\n",
      "validation: epoch 48, loss -0.000143290453706868,  {'acc': 0.498, 'baseline': -0.49681249999999033, 'loss': -0.498, 'sender_entropy': tensor(0.0016), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3290e-08)}\n",
      "validation: epoch 49, loss -4.9322628910886124e-05,  {'acc': 0.498, 'baseline': -0.49677551020408744, 'loss': -0.498, 'sender_entropy': tensor(0.0003), 'receiver_entropy': tensor(0.0004), 'executive_sender_entropy': tensor(1.3307e-08)}\n",
      "validation: epoch 50, loss -0.00014577990805264562,  {'acc': 0.498, 'baseline': -0.49675999999999565, 'loss': -0.498, 'sender_entropy': tensor(0.0012), 'receiver_entropy': tensor(0.0006), 'executive_sender_entropy': tensor(1.3335e-08)}\n"
     ]
    }
   ],
   "source": [
    "game = MultiAgentGame(senders, receivers, executive_senders, loss)\n",
    "sender_params = [{'params': sender.parameters(), 'lr': opts.lr} for sender in senders]\n",
    "executive_senders_params = [{'params': ex_sender.parameters(), 'lr': opts.lr} for ex_sender in executive_senders]\n",
    "receiver_params = [{'params': receiver.parameters(), 'lr': opts.lr} for receiver in receivers]\n",
    "optimizer = torch.optim.Adam(sender_params+receiver_params+executive_senders_params)\n",
    "\n",
    "neptune.init('tomekkorbak/EGG')\n",
    "trainer = CustomTrainer(game=game, optimizer=optimizer, train_data=train_loader, validation_data=test_loader)\n",
    "experiment = neptune.create_experiment(name='first-egg-experiment', tags=['egg', 'executive-senders'], params=vars(opts))\n",
    "trainer.monitor = NeptuneMonitor(experiment=experiment)\n",
    "trainer.train(n_epochs=opts.n_epochs)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool((torch.Tensor([[1, 1,], [2, 2]]) == torch.Tensor([[1, 1,], [2, 2]])).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "neptune": {
   "notebookId": "b69eb419-3ef8-46f1-98ea-abeb77b5106e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
